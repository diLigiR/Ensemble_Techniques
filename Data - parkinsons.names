Title: Parkinsons Disease Data Set

Abstract: Oxford Parkinson's Disease Detection Dataset

-----------------------------------------------------	

Data Set Characteristics: Multivariate
Number of Instances: 197
Area: Life
Attribute Characteristics: Real
Number of Attributes: 23
Date Donated: 2008-06-26
Associated Tasks: Classification
Missing Values? N/A

-----------------------------------------------------	

Source:

The dataset was created by Max Little of the University of Oxford, in 
collaboration with the National Centre for Voice and Speech, Denver, 
Colorado, who recorded the speech signals. The original study published the 
feature extraction methods for general voice disorders.

-----------------------------------------------------

Data Set Information:

This dataset is composed of a range of biomedical voice measurements from 
31 people, 23 with Parkinson's disease (PD). Each column in the table is a 
particular voice measure, and each row corresponds one of 195 voice 
recording from these individuals ("name" column). The main aim of the data 
is to discriminate healthy people from those with PD, according to "status" 
column which is set to 0 for healthy and 1 for PD.

The data is in ASCII CSV format. The rows of the CSV file contain an 
instance corresponding to one voice recording. There are around six 
recordings per patient, the name of the patient is identified in the first 
column.For further information or to pass on comments, please contact Max 
Little (littlem '@' robots.ox.ac.uk).

Further details are contained in the following reference -- if you use this 
dataset, please cite:
Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 
'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', 
IEEE Transactions on Biomedical Engineering (to appear).

-----------------------------------------------------

Attribute Information:

Matrix column entries (attributes):
name - ASCII subject name and recording number
MDVP:Fo(Hz) - Average vocal fundamental frequency////////////
MDVP:Fhi(Hz) - Maximum vocal fundamental frequency////////////
MDVP:Flo(Hz) - Minimum vocal fundamental frequency////////////
MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several /////////////
measures of variation in fundamental frequency
MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude//////////////
NHR,HNR - Two measures of ratio of noise to tonal components in the voice-----Pair Plot Done
status - Health status of the subject (one) - Parkinson's, (zero) - healthy 
RPDE,D2 - Two nonlinear dynamical complexity measures///////////-----Pair Plot Done
DFA - Signal fractal scaling exponent//////--Pair Plot Done
spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation ////////////---Pair Plot Done

-----------------------------------------------------

Citation Request:

If you use this dataset, please cite the following paper: 
'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', 
Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. 
BioMedical Engineering OnLine 2007, 6:23 (26 June 2007)


Index(['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:APQ',
       'NHR', 'HNR', 'status', 'RPDE', 'DFA', 'D2', 'PPE'],
      dtype='object')
	  
	  
**The data has 195 rows/obsevations and 24 columns/attributes.All the independent variables are continuous in nature and no null value is present.The name attribute should be dropped as it will not be used for final model building.**


**Although the data will not require imputation as it has no categorical independent variables , it will require standardization as the models we will be using are all affected by 
range of continuous variables such as KNN etc.We amy also need to remove outliers, however since there are very few observations in the given data, this may not be possible.The other challenges that we may face during model building is that there are a lot of attributes and we may need to drop the attributes that have a very high correlation.**


LOGISTIC REGRESSION - 83
NAIVE BAYES - 79
KNN - 88
Decision Tree - 79
Bagging - 79
Boosting -  88

Before discussing the efficacy of various algorithms, we must discuss the limitation of the given dataset.The data provided to us has only 195 instances.Out of which around 145 
patients have Parkinsons while rest dont.The total number of samples is very low and it is also not a true representation of the overall samples possible in a society.The less number of samples makes it possible for some of our models to overfit causing low accuracy in testing data.

If we look at the models we have implemented on the given dataset , we see that KNN has higher testing accuracy, but we should note that KNN has 100% accuracy on testing data indicating that it overfitted on the given dataset. In an ideal situation ensemble models almost always have higher accuracy over the simple supervised learning classifiers.
However , we see that bagging is having accuracy similar or even lower than other methods. This is because boosting depends on samples from the original dataset. Since the original
dataset is itself small , the bagging method does not improve accuracy of our predictions.Boosting method on the other hand gives better accuracy as it increases the weight of each 
misclassified attribute.

Although we expected the ensemble models to perform better which bossting does and gives a higher accuracy of 88% but it also causes  overfitting. On the other hand Naive Bayes 
may have given lower accuracy than Boosting but the training and testing data suggests that it does not overfit. Hence it is the best algorithm in the given scenario.































